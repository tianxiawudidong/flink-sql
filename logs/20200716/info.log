2020-07-16 10:34:58.515 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - 111111111
2020-07-16 10:34:58.520 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE active_users (
  created_at STRING,
  tid smallint,
  uid bigint,
  updated_at STRING,
  url STRING,
  ip STRING,
  ts AS TO_TIMESTAMP(created_at),
  WATERMARK FOR ts AS ts - INTERVAL '5' SECOND
) WITH (
  'connector.type' = 'kafka',
  'connector.version' = '0.11',
  'connector.topic' = 'icdc_log_test',
  'connector.startup-mode' = 'latest-offset',
  'connector.properties.zookeeper.connect' = '192.168.9.129:2181,192.168.9.130:2181,192.168.9.131:2181,192.168.9.132:2181,192.168.9.133:2181',
  'connector.properties.bootstrap.servers' = '192.168.9.129:9092,192.168.9.130:9092,192.168.9.131:9092,192.168.9.132:9092,192.168.9.133:9092',
  'connector.properties.group.id' = 'flink_group_11',
  'format.type' = 'csv',
  'format.derive-schema' = 'true'
)
2020-07-16 10:34:58.522 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE active_users (
  created_at STRING,
  tid smallint,
  uid bigint,
  updated_at STRING,
  url STRING,
  ip STRING,
) PARTITIONED BY (dt STRING, hr STRING, min STRING) STORED AS parquet TBLPROPERTIES (
  'partition.time-extractor.timestamp-pattern'='$dt $hr:$min:00',
  'sink.partition-commit.trigger'='partition-time',
  'sink.partition-commit.delay'='5 m',
  'sink.partition-commit.policy.kind'='metastore,success-file'
)
2020-07-16 10:49:22.968 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE active_users (
  created_at STRING,
  tid smallint,
  uid bigint,
  updated_at STRING,
  url STRING,
  ip STRING,
  ts AS TO_TIMESTAMP(created_at, 'yyyy-MM-dd HH:mm:ss'),
  WATERMARK FOR ts AS ts - INTERVAL '5' SECOND
) WITH (
  'connector.type' = 'kafka',
  'connector.version' = '0.11',
  'connector.topic' = 'icdc_log_test',
  'connector.startup-mode' = 'latest-offset',
  'connector.properties.zookeeper.connect' = '192.168.9.129:2181,192.168.9.130:2181,192.168.9.131:2181,192.168.9.132:2181,192.168.9.133:2181',
  'connector.properties.bootstrap.servers' = '192.168.9.129:9092,192.168.9.130:9092,192.168.9.131:9092,192.168.9.132:9092,192.168.9.133:9092',
  'connector.properties.group.id' = 'flink_group_11',
  'format.type' = 'csv',
  'format.derive-schema' = 'true'
)
2020-07-16 10:49:22.983 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE active_users (
  created_at STRING,
  tid smallint,
  uid bigint,
  updated_at STRING,
  url STRING,
  ip STRING,
) PARTITIONED BY (dt STRING, hr STRING, min STRING) STORED AS parquet TBLPROPERTIES (
  'partition.time-extractor.timestamp-pattern'='$dt $hr:$min:00',
  'sink.partition-commit.trigger'='partition-time',
  'sink.partition-commit.delay'='5 m',
  'sink.partition-commit.policy.kind'='metastore,success-file'
)
2020-07-16 11:06:42.393 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE kafka_table (
  created_at STRING,
  tid SMALLINT,
  uid BIGINT,
  updated_at STRING,
  url STRING,
  ip STRING
) WITH (
  'connector.type' = 'kafka',
  'connector.version' = '0.11',
  'connector.topic' = 'icdc_log_test',
  'connector.startup-mode' = 'latest-offset',
  'connector.properties.zookeeper.connect' = '192.168.9.129:2181,192.168.9.130:2181,192.168.9.131:2181,192.168.9.132:2181,192.168.9.133:2181',
  'connector.properties.bootstrap.servers' = '192.168.9.129:9092,192.168.9.130:9092,192.168.9.131:9092,192.168.9.132:9092,192.168.9.133:9092',
  'connector.properties.group.id' = 'flink_group_11',
  'format.type' = 'csv',
  'format.derive-schema' = 'true'
)
2020-07-16 11:06:42.400 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - CREATE TABLE active_users (
  created_at STRING,
  tid SMALLINT,
  uid BIGINT,
  updated_at STRING,
  url STRING,
  ip STRING,
) PARTITIONED BY (dt STRING, hr STRING, min STRING) STORED AS parquet TBLPROPERTIES (
  'partition.time-extractor.timestamp-pattern'='$dt $hr:$min:00',
  'sink.partition-commit.trigger'='process-time',
  'sink.partition-commit.policy.kind'='metastore,success-file'
)
2020-07-16 16:43:57.268 [main] INFO  com.ifchange.flink.sql.hive.FlinkStreamHiveTest - INSERT INTO active_users 
SELECT created_at, tid, uid, updated_at, url, ip,
 TO_DATE(created_at, 'yyyy-MM-dd'),
  HOUR(TO_TIMESTAMP(created_at, 'yyyy-MM-dd HH:mm:ss')),
 MINUTE(TO_TIMESTAMP(created_at, 'yyyy-MM-dd HH:mm:ss')) 
FROM kafka_table
